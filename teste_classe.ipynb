{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 16:48:41 WARN Utils: Your hostname, daniel-Aspire-A315-56 resolves to a loopback address: 127.0.1.1; using 192.168.0.42 instead (on interface wlp0s20f3)\n",
      "23/03/06 16:48:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/03/06 16:48:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 16:48:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "spark = SparkSession.builder.config('spark.jars', 'aws-java-sdk-bundle-1.12.419.jar,hadoop-aws-3.3.2.jar') \\\n",
    "                            .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "# spark = SparkSession.builder.config('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.0.0,com.google.guava:guava:23.0').config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider') \\\n",
    "#                             .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.2\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_ACCESSKEY = \"oy9WWsyFNw4lFX3P\"\n",
    "MINIO_SECRETKEY = \"ZQf5hwB9BYsN0fLjSTOlpZ560uXrZHZD\"\n",
    "\n",
    "\n",
    "\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://127.0.0.1:9000\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", MINIO_ACCESSKEY)\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", MINIO_SECRETKEY)\n",
    "spark._jsc.hadoopConfiguration().set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark._jsc.hadoopConfiguration().set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "spark._jsc.hadoopConfiguration().set(\"park.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------+------------+----------------+---------------+-----------+------+--------+----------------------------------+---------------------------------------+-------------------------------------+---------+------------------------+-----------+-----------------------+--------------------------------+------+----------+------------------+-------------------+----+----+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+\n",
      "|_c0   |_c1|_c2     |_c3         |_c4             |_c5            |_c6        |_c7   |_c8     |_c9                               |_c10                                   |_c11                                 |_c12     |_c13                    |_c14       |_c15                   |_c16                            |_c17  |_c18      |_c19              |_c20               |_c21|_c22|_c23                    |_c24                  |_c25                    |_c26                  |_c27                    |_c28                  |_c29                    |_c30                  |\n",
      "+------+---+--------+------------+----------------+---------------+-----------+------+--------+----------------------------------+---------------------------------------+-------------------------------------+---------+------------------------+-----------+-----------------------+--------------------------------+------+----------+------------------+-------------------+----+----+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+\n",
      "|Bairro|CEP|Completa|Código (CNS)|Data da Assunção|Data da criação|Denominação|E-mail|Endereço|Funcionários em Regime Estatutário|Funcionários em Regime de Contração CLT|Horário de Funcionamento da Serventia|Município|Possui Acesso à Internet|Responsável|Serventia Informatizada|Situação jurídica do responsável|Status|Substituto|Telefone Principal|Telefone Secundário|Tipo|UF  |mês referência 0 periodo|mês referência 0 valor|mês referência 1 periodo|mês referência 1 valor|mês referência 2 periodo|mês referência 2 valor|mês referência 3 periodo|mês referência 3 valor|\n",
      "+------+---+--------+------------+----------------+---------------+-----------+------+--------+----------------------------------+---------------------------------------+-------------------------------------+---------+------------------------+-----------+-----------------------+--------------------------------+------+----------+------------------+-------------------+----+----+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cartorios = spark.read.csv('s3a://data-product-a/landing/df_cartorios/')\n",
    "\n",
    "df_cartorios.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 16:53:56 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "23/03/06 16:53:57 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "23/03/06 16:53:57 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_cartorios.write.csv('s3a://data-product-a/landing/teste/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30506"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cartorios.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
